@InProceedings{2015_EA_16,
author    = {Carpentier, Thibaut},
title     = {Binaural synthesis with the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {0--7},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {The Web Audio API is a powerful new platform for audio rendering within the browser and it provides a great opportunity for large deployment of audio applications. This paper explores the possibilities and limitations of the API for 3D sound spatialization based on binaural synthesis over headphones. The paper examines different processing structures and presents a new web-based server which allows the user to load individualized Head-Related Transfer Functions from a remote database.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_16.pdf:pdf},
keywords  = {3d audio,binaural rendering,dio api,hrtf,sound spatialization,virtual loudspeakers,web au-},
type      = {Poster},
}

@Misc{2015_vid4,
author    = {Arias, Emilio Jes√∫s Gallego},
title     = {Can Web Audio be Liberated from the Von Neumann Style?},
month     = jan,
year      = {2015},
abstract  = {The audio programming world is extremely prolific in domain-specific languages. Programmers and musicians prefer a custom-tailored environment where their high-level ideas can be better expressed and implemented thanks to specific domain knowledge. In particular, strongly typed functional programming has become an ideal platform for audio programming, thanks to a concise, high-level writing style, high reusability, and ability to avoid mistakes and improve error handling. - How may Web Audio benefit from these ideas? - How may such languages benefit from Web Audio? In this talk, we will use the functional audio programming language Faust as the reference DSL, to discuss a formal theory of interoperable and efficient audio components. Particular emphasis will be made on the use of strong, functional-style type-systems. We will address performance, security, and practical considerations, and reflect on the relationship of such theoretical framework to the actual standard.},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/85dca677d30c78960440344f9ddaa9b039230601.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Talk},
url       = {https://medias.ircam.fr/x396729},
}

@Misc{2015_vid1,
author    = {Vinet, Hugues and Schnell, Norbert and Goldszmidt, Samuel},
title     = {WAC 2015 Introduction},
month     = jan,
year      = {2015},
abstract  = {Web Audio Conference 2015 Introduction},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/4d334ebf9f2b4800ad2e49dba876fa71ac0ae028.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Talk},
url       = {https://medias.ircam.fr/x4116d0},
}

@Misc{2015_vid3,
author    = {Santell, Jordan},
title     = {Web Audio Tools},
month     = jan,
year      = {2015},
abstract  = {As technologies evolve and mature, proper tooling is needed to increase adoption and combat complexity. Web audio is no exception. An overture on the state of web audio tools, we will explore using both browser developer tools that take advantage of privileged platform code, and cross-browser drop-in libraries to provide introspection of the state of an audio context and nodes. With these tools, we'll cover common debugging scenarios like audio graph construction, node-to-node signal transformations, signal visualizations, garbage collection, and resource consumption. These tools can help beginners understand a complex new API, save a developer's time debugging, and help browser implementers optimize their platform. Attendees will leave with the knowledge of what tools are out there, workflows for inspecting, fixing, and optimizing a web audio environment, and how to make their own tools for a specific use case.},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/73f411709764f7a6c267e0cc65489ea0f4c5171e.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Talk},
url       = {https://medias.ircam.fr/x32ba00},
}

@Misc{2015_vid2,
author    = {Monschke, Jan},
title     = {Building a Collaborative Digital Audio Workstation Based on the Web Audio API},
month     = jan,
year      = {2015},
abstract  = {The introduction of the Web Audio API has enriched the web landscape enormously. It gives game developers the ability to add precisely timed, high performant sound effects and to create realistic spatialized sound landscapes. For many web developers it is the first time they encounter audio programming which leads to many interesting experiments when the world of web and audio collide. Traditional web developers start to become really interested in audio programming and educate themselves on the topic of synthesizers and audio effects. However, currently there are only few applications that try to create more sophisticates audio production tools in the browser. In this talk I want to show how I used the Web Audio API and other emerging web standards like WebRTC to create a collaborative digital audio workstation. It allows users to record, arrange and create their own songs in collaboration with other users in real time. http://web-audio-editor.herokuapp.com/},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/1a379c1f0bf0ae4f7ad028b8476f7791fdd9d570.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Talk},
url       = {https://medias.ircam.fr/x7bde3a},
}

@InProceedings{2015_23,
author    = {Kleimola, Jari},
title     = {DAW Plugins for Web Browsers},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {A large collection of Digital Audio Workstation (DAW) plugins is available on the Internet in open source form. This paper explores their reuse in browser environments, focusing on hosting options that do not require manual installation. Two options based on Emscripten and PNaCl are introduced, implemented, evaluated, and released as open source. We found that ported DAW effect and sound synthesizer plugins complement and integrate with the Web Audio API, and that the existing preset patch collections make the plugins readily usable in online contexts. The latency measures are higher than in native plugin implementations, but expected to reduce with the emerging AudioWorker node.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Kleimola - 2015 - DAW Plugins for Web Browsers.pdf:pdf},
issn      = {2663-5844},
keywords  = {daw plugin host,emscripten,ladspa,pnacl,web browser},
type      = {Paper},
url       = {https://medias.ircam.fr/xe6608e},
}

@InProceedings{2015_EA_15,
author    = {Ziya, Ehsan},
title     = {Scrolling Through Sound - Scrolling as a method of interaction with audio on the web},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper aims to investigate the creative uses of scrolling as an interaction method for navigating through sound and music. Mainly focused on the use of granular synthesis, the paper explores the interaction model and technical challenges and presents a prototype as proof of concept to demonstrate a case in which scrolling can be used to create an immersive and interactive audio experience on the web. Link to prototype: zya.github.io/scrollsound},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_15.pdf:pdf},
keywords  = {generative,granular synthesis,interactive audio,javascript,music,scrolling,web audio api},
type      = {Poster},
}

@InProceedings{2015_40,
author    = {Mann, Yotam},
title     = {Interactive Music with Tone.js},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper discusses the features, architecture and implementation of Tone.js, a Web Audio framework to facilitate the creation of interactive music specifically suited to the affordances of the browser.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Mann - 2015 - Interactive Music with Tone.js.pdf:pdf},
issn      = {2663-5844},
keywords  = {Design,Effects,Human Factors Keywords Signal Processing,J12 [Human-centered computing]: Web-based interac-,Library,Music,Performance,Synthesis,Web Audio API},
type      = {Paper},
url       = {https://medias.ircam.fr/x9d4352},
}

@Misc{2015_KN2,
author    = {Lowis, Chris},
title     = {Keynote #2 The First Computer Music Programming Language},
month     = jan,
year      = {2015},
abstract  = {MUSIC was a programming language developed by Max Mathews at Bell Labs in 1957. In this talk we'll learn more about Max Mathews, the origins of computer music, and by building a compiler for MUSIC in JavaScript hear what some of the very first computer music compositions sounded like. Chris Lowis is an invited expert on the W3C's Audio Working group. He studied acoustics and signal processing at the Institute of Sound and Vibration Research in Southampton, and recently worked at the R&D department at the BBC. He loves to use the Web Audio API to bring old synthesisers back to life, and to write about audio on the web in his newsletter Web Audio Weekly.},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/b7978a2345bc334c445ead30ac9bf7870b987d9c.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Keynote},
url       = {https://medias.ircam.fr/x6f0394},
}

@Misc{2015_KN1,
author    = {Wilson, Chris},
title     = {Keynote #1 Audio and the Web},
month     = jan,
year      = {2015},
abstract  = {The web has supported multiple media since its inception - however, only recently has it become a viable platform for building audio applications. The talk will examine the journey of audio in the web platform, the intersection of interesting technologies that make this a pivotal point for audio and the web, and will highlight the opportunities unlocked by web audio and where we go from here. Chris Wilson is a Developer Advocate on the Google Chrome team. He started working on web browsers in 1993 when he co-authored the original Windows version of NCSA Mosaic before working on Internet Explorer for fifteen years at Microsoft. He has separate and combined passions for digital audio, music and the web, and co-edits the Web Audio and Web MIDI specifications at the W3C. He also specializes in playing many different instruments badly.},
address   = {Paris},
booktitle = {Proceedings of the International Web Audio Conference},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/f229cbafd45cf4048cd1a5c32e1434cd9d978a9f.html:html},
publisher = {IRCAM},
series    = {WAC '15},
type      = {Keynote},
url       = {https://medias.ircam.fr/x8fe5fb},
}

@InProceedings{2015_17,
author    = {Rawlinson, Hugh and Segal, Nevo and Fiala, Jakub},
title     = {Meyda: an audio feature extraction library for the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
pages     = {1--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {There are many existing native libraries and frameworks for audio feature extraction used in multimedia information retrieval. Many are dependent on highly optimised low level code to cope with the high performance requirements of realtime audio analysis. In this paper, we present a new audio feature extractor library, Meyda, for use with the JavaScript Web Audio API, and detail its benchmarking results. Meyda provides the first library for audio feature extraction in the web client, which will enable music information retrieval systems, complex visualisations and a wide variety of technologies and creative projects that previously were relegated to native software. The Meyda project, including source code and documentation is released under an MIT license.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Fiala, Segal, Rawlinson - 2015 - Meyda an audio feature extraction library for the Web Audio API.pdf:pdf},
issn      = {2663-5844},
keywords  = {Audio Feature Extraction,Music Information Retrieval,Web Audio},
type      = {Paper},
url       = {https://medias.ircam.fr/x8fbaf8},
}

@InProceedings{2015_26,
author    = {Wyse, Lonce},
title     = {Spatially Distributed Sound Computing and Rendering Using the Web Audio Platform},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Large multi-channel spatial audio systems have historically been play-grounds for universities and well-funded studios, but only a dream for independent composers. Similarly, "parallel computers" were locked in research facilities, where only a few musicians ever gained access to, for example, the compute power to convolve hundreds of separate audio streams with spatially- specific room impulse responses. Mobile devices in the hands of audiences can quickly configure themselves into such systems at very affordable (and distributed) cost and little effort, making powerful and expressive spatially distributed musical platforms accessible to anyone today. We describe some software systems and artistic works that have been developed recently to explore some of the spatial audio capabilities of the mobile device browser platform.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Wyse - 2015 - Spatially Distributed Sound Computing and Rendering Using the Web Audio Platform.pdf:pdf},
issn      = {2663-5844},
keywords  = {audience participation,distributed computing,interactive audio,spatial audio,web audio api},
type      = {Paper},
url       = {https://medias.ircam.fr/xf88009},
}

@InProceedings{2015_8,
author    = {Schoeffler, Michael and St√∂ter, Fabian-Robert and Edler, Bernd and Herre, J√ºrgen},
title     = {Towards the Next Generation of Web-based Experiments: A Case Study Assessing Basic Audio Quality Following the ITU-R Recommendation BS. 1534 (MUSHRA)},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {1534},
series    = {WAC '15},
pages     = {1--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Listening tests are widely used to assess the quality of audio systems. The majority of such listening tests is conducted in controlled environments with selected participants and professional audio equipment. In the last few years, conducting listening tests over the Internet, as so called web-based experiments, has become popular. A recent study has shown that web-based experiments lead to comparable results as laboratory experiments. Until now, it was only possible to implement a limited number of listening test types as web-based experiments because web standards were missing some crucial features, e. g. sample manipulation of audio streams. With the upcoming of the Web Audio API, a much wider range of listening test types can be implemented as new audio processing features have been introduced. This paper demonstrates which new possibilities are enabled by the Web Audio API. To this end, the ITU-R Recommendation BS.1534 (MUSHRA) is taken as an example.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Schoeffler et al. - 2015 - Towards the Next Generation of Web-based Experiments A Case Study Assessing Basic Audio Quality Following the.pdf:pdf},
issn      = {2663-5844},
keywords  = {1534,itu-r recommendation bs,mushra,web-based ex-},
type      = {Paper},
url       = {https://medias.ircam.fr/x5feecb},
}

@InProceedings{2015_EA_13,
author    = {Pendharkar, Chinmay and B√§ck, Peter and Wyse, Lonce},
title     = {A Dynamic Audio Experience creation platform in Web Audio},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper describes innovative aspects of the Sonoport Studio, a dynamic audio experience creation platform which will be presented in a demonstration at the 1st Web Audio Conference in Paris. Two key components of the platform are 1) Sound Model templates that represent classes of dynamic sonic behaviors, and 2) Interaction Model templates that represent classes of interactive behavior that are commonly mapped to interactive sound elements. These components, together with a database of sound files and other authoring tools, comprise an interactive audio experience creation platform which is aimed at a typical creative web designer/developer who wants to take advantage of the new capabilities offered by the Web Audio platform, but may not have a deep synthesis or audio processing background.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_13.pdf:pdf},
keywords  = {audio synthesis,interactive audio,w3c web audio api},
type      = {Poster},
}

@InProceedings{2015_22,
author    = {Walker, William and Belet, Brian},
title     = {Birds of a Feather (Les Oiseaux de M√™me Plumage): Dynamic Soundscapes using Real-time Manipulation of Locally Relevant Birdsongs},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper and live audio demonstration explores the capabilities of using Web Audio API as a digital audio workstation (DAW) to manipulate sounds from massive server-side databases. Sonic source material comes from a database of birdsongs recorded worldwide by volunteer recordists at xeno-canto.org. Sounds from xeno-canto are chosen to match recent, nearby bird sightings submitted by volunteer birders at eBird. The result is a virtual soundscape derived from the sounds of birds currently present in the user's geographical region. Our client-server architecture delegates database queries and archival storage to the server, leaving the client to concentrate on the aesthetic context of sound modification and manipulation. Engineering issues include separation of client versus server concerns and mashups of crowdsourced databases. Aesthetic issues include which tasks are automated server-side, which are user-controlled client-side, and why. Social issues include single user versus multiple user paradigms, artistic soundscape composition versus commercial applications (e.g., games with evolving sound tracks) using public domain sound sources, music as foreground art versus background audio content, and the larger role of sound and music in current society. Audio results will be demonstrated as each topic is addressed. All the source code for this project is free available under the MIT License at [https://github.com/wfwalker/loco-xeno-canto]. A live demo is at [http://birdwalker.com:9090/quartet.html]},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Walker, Belet - 2015 - Birds of a Feather ( Les Oiseaux de M{\^{e}}me Plumage ) Dynamic Soundscapes using Real-time Manipulation of Locally R.pdf:pdf},
issn      = {2663-5844},
keywords  = {ds of a feather,dynamic soundscapes using real-time,les oiseaux de m√™me,locally relevant birdsongs,manipulation of,plumage},
type      = {Paper},
}

@InProceedings{2015_12,
author    = {Pendharkar, Chinmay and B√§ck, Peter and Wyse, Lonce},
title     = {Adventures in scheduling, buffers and parameters: Porting a dynamic audio engine to Web Audio},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {At Sonoport, we ported our Dynamic Sound Engine from Adobe's Flash technology to Web Audio. The difference in approaches to threading, scheduling and parameters between Flash and Web Audio created a few challenges for us. These differences and some peculiarities of Web Audio required workarounds to be able to implement our Dynamic Sound Engine in Web Audio. In this paper we discuss three of these workarounds dealing with creating Parameters, scheduling operations and playback position of buffers, and explain how these work-arounds, although not optimal solutions, allowed us to support our use cases. Finally we consider how the upcoming AudioWorker change in the Web Audio specification, is expected to impact these workarounds.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Pendharkar, B{\"{a}}ck, Wyse - 2015 - Adventures in scheduling, buffers and parameters Porting a dynamic audio engine to Web Audio.pdf:pdf},
keywords  = {audio synthesis,interactive audio,w3c web audio api},
type      = {Paper},
url       = {https://medias.ircam.fr/x71a427},
}

@InProceedings{2015_24,
author    = {Pike, Chris and Taylour, Peter and Melchior, Frank},
title     = {Delivering Object-Based 3D Audio Using The Web Audio API And The Audio Definition Model},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {2--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents an application that demonstrates object-based 3D audio rendering in the web browser using the Web Audio API. The application loads audio files containing object-based meta-data and provides head-tracked dynamic binaural rendering of the content to create an immersive 3D audio experience for headphone listeners. The user can interact with the rendering by muting individual audio objects and switching between the binaural rendering mode and conventional stereo rendering. This application demonstrates the future of broadcast sound experiences over the web, where immersive content is rendered on the client and can be adapted to listener context, as page layout is adapted to device context today with responsive design.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Pike, Taylour, Melchior - 2015 - Delivering Object-Based 3D Audio Using The Web Audio API And The Audio Definition Model.pdf:pdf},
isbn      = {0199537992},
issn      = {2663-5844},
keywords  = {audio definition,object-based broadcasting,web audio api},
type      = {Paper},
url       = {https://medias.ircam.fr/x2ad0c5},
}

@InProceedings{2015_3,
author    = {Mahadevan, Anand and Freeman, Jason and Magerko, Brian and Martinez, Juan Carlos},
title     = {EarSketch: Teaching Computational Music Remixing in an Online Web Audio Based Learning Environment},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {0--5},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {EarSketch is a novel approach to teaching computer science concepts via algorithmic music composition and remixing in the context of a digital audio workstation paradigm. This project includes a Python/Javascript coding environment, a digital audio workstation view, an audio loop browser, a social sharing site and an integrated curriculum. EarSketch is aimed at satisfying both artistic and pedagogical goals of introductory courses in computer music and computer science. This integrated platform has proven particularly effective at engaging culturally and economically diverse students in computing through music creation. EarSketch makes use of the Web Audio API as its primary audio engine for playback, effects processing and offline rendering of audio data. This paper explores the technical framework of EarSketch in greater detail and discusses the opportunities and challenges associated with using the Web Audio API to realize the project.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Mahadevan et al. - 2015 - EarSketch Teaching Computational Music Remixing in an Online Web Audio Based Learning Environment.pdf:pdf},
keywords  = {2015 for the individual,authors,copying,copyright,cs education,music composition,papers by the papers,remixing,social media sharing,web audio},
type      = {Paper},
}

@InProceedings{2015_EA_18,
author    = {Buffa, Michel and Hallili, Amine and Gonin, Philippe Renevier},
title     = {MT5: a HTML5 multitrack player for musicians},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {MT5 is a multitrack player based on the Web Audio API [1]. It's open source, runs on multiple devices (all recent desktop browsers except IE, all IOS browsers based on Safari Mobile, Android Chrome, Opera and Firefox mobile). It has been entirely developed in a web browser using the Cloud9 online JavaScript IDE. A demo version can be tried online at http://mt5demo.gexsoft.com while another version that proposes rock classics song by original artists has a restricted access (http://mt5.gexsoft.com).},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_18.pdf:pdf},
keywords  = {e-learning,javascript,web audio,web based ide},
type      = {Poster},
}

@InProceedings{2015_39,
author    = {Roma, Gerard and Serra, Xavier},
title     = {Music performance by discovering community loops},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Technologies for discovering sounds in large databases can help breaking the boundary between exploration and music performance. In this paper, we present a system for exploring loops from Freesound. Sound files are grouped by their most common repetition periods, so that they can be played in sync. A graph layout algorithm is used to organize sounds in a two-dimensional plane so that loops with similar timbre are spatially close. The result is a system that can be used as a musical instrument: since sounds will always play in sync, the user can freely explore the variety of sounds uploaded by the Freesound community, while continuously producing a rhythmic music stream.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Roma, Serra - 2015 - Music performance by discovering community loops.pdf:pdf},
keywords  = {Audio discovery,music loops,web audio},
type      = {Paper},
}

@InProceedings{2015_EA_2,
author    = {Barat√®, Adriano and Haus, Goffredo and Ludovico, Luca A and Baldan, Stefano and Mauro, Davide A},
title     = {Music-Related Media-Contents Synchronization over the Web: the IEEE 1599 Initiative},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
number    = {Lim},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {IEEE 1599 is an international standard originally conceived for music, which aims at providing a comprehensive description of the media contents related to a music piece within a multi-layer and synchronized environment. A number of off-line and stand-alone software prototypes has been realized after its standardization, occurred in 2008. Recently, thanks to some technological advances (e.g. the release of HTML5), the engine of the IEEE 1599 parser has been ported on the Web. Some non-trivial problems have been solved, e.g. the management of multiple simultaneous media streams in a client-server architecture. After providing an overview of the IEEE 1599 standard, this article presents a survey of the recent initiatives regarding audio-driven synchronization over the Web.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_2.pdf:pdf},
keywords  = {H53 [Gro,H55 [Sound and Music Computing]: Systems,Synchronization,Web applications,XML},
type      = {Poster},
}

@InProceedings{2015_29,
author    = {Geronazzi, Michele and Kleimola, Jari and Majdac, Piotr},
title     = {Personalization support for binaural headphone reproduction in web browsers},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {111},
number    = {479},
series    = {WAC '15},
pages     = {1009--1010},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This study consider the issue of providing and individual listening experience for binaural sound reproduction in web browsers via headphones. The proposed solution aims at building a web framwork with Web Audio API, giving support to the download of head-related trafer functions (HRTFs) associated with listener's personal profile from a server and the synchronization between the listener's devices. With each playback device and listener, the individual headphone equalization filters will be computed from headphone transfer functions (HpTFs) stored on the server. At server side, we propose to store the HRTFs and HpTFs in spatially oriented format for acoustics (SOFA). At client-side, we propose to convert the data to a new structure (WAV) ensuring a compatible solution with existing Web Audio API implementations. A binaural rendering implementation in JavaScript acting as a proof-of-concept reveals critical issues related to the native implementation in web browsers.},
doi       = {10.1192/bjp.111.479.1009-a},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Geronazzi, Kleimola, Majdac - 2015 - Personalization support for binaural headphone reproduction in web browsers.pdf:pdf},
issn      = {2663-5844},
type      = {Paper},
url       = {https://medias.ircam.fr/x487d49},
}

@InProceedings{2015_27,
author    = {Saiz, Victor and Matuszewski, Benjamin and Goldszmidt, Samuel and Stravinsky, Place Igor},
title     = {Audio oriented UI components for the web platform},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
pages     = {1--5},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents a set of web-native tools for visualising and interacting with time-based objects. These visualisations are rendered as part of the document using web standard technologies, allowing for an easy integration and interaction with the elements on the same document without the help of non-native technologies such as Adobe Flash, Microsoft's Silverlight or Oracle's Java.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Saiz et al. - 2015 - Audio oriented UI components for the web platform.pdf:pdf},
keywords  = {ecmascript,graphical user interface,html5,interaction,open web standards,visualisation,web components},
type      = {Paper},
url       = {https://medias.ircam.fr/xfaebad},
}

@InProceedings{2015_7,
author    = {Paradis, Matthew and Gregory-Clarke, Rebecca and Melchior, Frank},
title     = {VenueExplorer, Object-Based Interactive Audio for Live Events},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {VenueExplorer is a new approach to broadcasting live events which gives more control to the audience than traditional viewing methods. Users can navigate around an ultra-high resolution video, zooming into the areas of the event which interest them and accessing extra content. VenueExplorer aims to be platform independent and runs in the browser. In this paper we describe the development of object-based audio rendering to create a more engaging and personalised experience than that of video alone. We use the Web Audio API (WAAPI) to process audio based on the users viewport. We also describe a library that has been developed as part of this project for the handling of location based audio objects.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Paradis, Gregory-Clarke, Melchior - 2015 - VenueExplorer , Object-Based Interactive Audio for Live Events.pdf:pdf},
issn      = {2663-5844},
keywords  = {broadcasting,object based audio,web audio api},
type      = {Paper},
}

@InProceedings{2015_14,
author    = {Lazzarini, Victor and Costello, Edward and Yi, Steven and Ffitch, John},
title     = {Extending Csound to the Web},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper discusses the presence of the sound and music computing system Csound in the modern world-wide web browser platform. It introduces the two versions of the system currently available, as pure Javascript code, and as portable Native Client binary module with a Javascript interface. Three example applications are presented, showing some of the potential uses of the system. The paper concludes with a discussion of the wider Csound application ecosystem, and the prospects for its future development.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Lazzarini et al. - 2015 - Extending Csound to the Web.pdf:pdf},
issn      = {2663-5844},
keywords  = {music programming languages,web applications},
type      = {Paper},
url       = {https://medias.ircam.fr/x0460cf},
}

@InProceedings{2015_33,
author    = {Taylor, Ben and Allison, Jesse},
title     = {BRAID: A Web Audio Instrument Builder with Embedded Code Blocks},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Braid (Browser Audio Interface and Database) is a web audio instrument-building environment developed with the NexusUI platform. To identify the requirements of such an environment, the utility of NexusUI as an audio interface engine for browser-based projects is reviewed. The addition of inline web audio within a drag-and-drop interface-building environment is discussed. A consideration of a modified Model-View-Controller architecture to integrate DSP code and interface is followed by an examination of the work-flow of designing browser-based instruments within Braid. Finally, a database for saving and sharing web audio instruments for performance or audience distribution is described.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Taylor, Allison - 2015 - BRAID A Web Audio Instrument Builder with Embedded Code Blocks.pdf:pdf},
issn      = {2663-5844},
keywords  = {audio,audio interface,creative code,digital,instrument design,live-coding user interface,mvc,web audio},
type      = {Paper},
url       = {https://medias.ircam.fr/xa87b09},
}

@InProceedings{2015_EA_31,
author    = {Rossignol, Mathias and Lafay, Gregoire and Lagrange, Mathieu and Misdarris, Nicolas},
title     = {SimScene: a web-based acoustic scenes simulator*},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {1--7},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {We introduce in this paper a soundscape simulator called SimScene, designed to be used as an experimental tool to characterize the mental representation of sound environments. The soundscape simulator allows a subject to generate a full sonic environment by sequencing and mixing sound elements , and manipulating their sound level and time positioning. To make the simulation process effective, SimScene has not be designed to manipulate individual parameters of individual sounds, but to specify high-level parameters for whole classes of sounds, organized into a hierarchical semantically structured dataset. To avoid any linguistic bias, a listening oriented interface allows subjects to explore the dataset without any text written help. The entire software is developed in Javascript using the standard Web Audio technology , and is thus fully supported by most modern web browsers. This fact should allow experimenters to adopt a crowdsourcing approach to experimentation in order to assess hypotheses on large populations, and facilitate the development of experimental protocols to investigate the influence of socio-cultural background on soundscape perception.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_31.pdf:pdf},
keywords  = {H55 [Sound and Music Computing]: Signal analysis,Human Factors Keywords sound perception,Simulation,and processing General Terms Audio,cognitive psychology,soundscape,synthesis,web-based acoustic scenes sim-ulator,web-based sound environment generator,web-based soundscape simulator},
type      = {Poster},
}

@InProceedings{2015_19,
author    = {Schnell, Norbert and Saiz, Victor and Barkati, Karim and Goldszmidt, Samuel},
title     = {Of Time Engines and Masters - An API for Scheduling and Synchronizing the Generation and Playback of Event Sequences and Media Streams for the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {In this article we present an API and a set of Javascript modules for the synchronized scheduling and aligned playback of predetermined sequences of events such as notes, audio segments, and parameter changes as well as media streams (e.g. audio buffers) based on the Web Audio API logical time. The API has been designed to facilitate the development on both ends, the implementation of modules which generate event sequences or media streams as well as the integration of such modules into complex audio applications that require flexible scheduling, playback and synchronization.},
file      = {:Users/Hjem/Library/Application Support/Mendeley Desktop/Downloaded/Schnell et al. - 2015 - Of Time Engines and Masters - An API for Scheduling and Synchronizing the Generation and Playback of Event Seque.pdf:pdf},
issn      = {2663-5844},
keywords  = {Audio Processing,HTML 5,Scheduling,Synchronization,Web Audio API},
type      = {Paper},
url       = {https://medias.ircam.fr/x6c8804},
}

@InProceedings{2015_EA_35,
author    = {Goldwaser, Rapha√´l and Freard, Emmanuel},
title     = {Streaming live content to web audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {7--10},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Web Audio API helps to manage sound through a web browser. In most cases, the input is a sound file, fully loaded from a server. Stored in the cache of the browser, it is then transformed using Web Audio API. But we can also want to work with segments of a file. For instance, when streaming live data, Web have to deal with a dataset of undetermined length.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_35.pdf:pdf},
keywords  = {1 audio processing,4,audio streaming,live streaming,real-time processing,technological choices},
type      = {Poster},
}

@InProceedings{2015_EA_37,
author    = {Roma, Gerard and Serra, Xavier},
title     = {Querying Freesound with a microphone},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {On the web, searching for sounds is usually limited to text queries. This requires adding textual descriptions to each audio file, which is indexed effectively as a text document. Recent developments in browser technologies allow developers to access the audio input or microphone of the computer, enabling Query by Example (QbE) applications. We present a demonstration system that allows users to make queries on Freesound.org by recording audio in the browser. A basic prototype is available online.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_37.pdf:pdf},
keywords  = {Query by example,audio retrieval,web audio},
type      = {Poster},
}

@InProceedings{2015_EA_25,
author    = {Mason, Andrew and Paradis, Matthew},
title     = {Adaptive, Personalised ''in browser'' Audio Compression},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {12--15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Audio quality is very important to the BBC's audience, and unwanted loudness variations reduce the quality of the listeners' experience. Dynamic range control applied by the broadcaster can go some way to avoiding problems but, because the broadcaster cannot take into account each listener's individual environment, needs, or preference, it cannot please everyone all the time. The listening conditions are a significant factor to be taken into account when dynamic range control is applied. The Web Audio API offers the possibility of performing dynamic range control under the control of the listener, tailoring it optimally for their individual situation. We have developed a system that demonstrates that this is achievable in a modern web browser. In it, a compressor is controlled automatically by the environmental noise level measured using the microphone present in most mobile device audio players.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_25.pdf:pdf},
keywords  = {broadcasting,object based audio,web audio api},
type      = {Poster},
}

@InProceedings{2015_EA_20,
author    = {Burleigh, Ian G. and Schaller, Thilo},
title     = {Quint.js: A JavaScript library for teaching music technology to fine arts students},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
number    = {September},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents quint.js, a JavaScript library for making interactive HTML/SVG/Web Audio ‚Äúapplets‚Äù. Two-dimensional geometric structures (‚Äúmachines‚Äù) that are based in SVG vector graphics with audible feedback synthesized through Web Audio are used to demonstrate various physical, acoustic, and psychoacoustic phenomena and are applied in teaching music technology courses to fine arts students. The current core quint.js library and extension modules are a starting point for more extensive integration of Web Audio to support the delivery of course content and for the creation of integrated, interactive lecture notes.},
doi       = {10.13140/RG.2.1.3575.9521},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_20.pdf:pdf},
keywords  = {audio,audio arts,audio engineering,ear training,instruction,javascript,svg,web},
type      = {Poster},
}

@InProceedings{2015_EA_30,
author    = {Robaszkiewicz, S√©bastien and Schnell, Norbert},
title     = {Soundworks - A Playground for Artists and Developers to Create Collaborative Mobile Web Performances},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {We present Soundworks, a Javascript framework that enables artists and developers to create collaborative music performances where a group of participants distributed in space use their smartphones to generate sound and light through touch and motion. The framework adopts a modular architecture to make it easy to implement different performance scenarios, using a server / client architecture supported by Node.js and socket.io. We provide a boilerplate that allows anyone to bootstrap a scenario for Soundworks and focus on its audiovisual and interaction design instead of the infrastructure. We developed three scenarios based on Soundworks: Wandering Sound, Drops, and Paths. Each scenario has been tested multiple times with teenagers during workshops at the Centre Pompidou's Studio 13/16 in Paris. We present the results of these live tests.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_30.pdf:pdf},
keywords  = {HTML5,Web Audio API,collect,mobile music,music},
type      = {Poster},
}

@InProceedings{2015_EA_32,
author    = {Denoux, Sarah and Letz, St√©phane and Orlarey, Yann and Fober, Dominique},
title     = {Composing a Web of Audio Applications},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {The Web offers a great opportunity to share, deploy and use programs without installation difficulties. In this article we explore the idea of freely combining/composing real-time audio applications deployed on the Web using Faust audio DSP language.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_32.pdf:pdf},
keywords  = {composability,dsp programming,faust,web},
type      = {Poster},
}